## 卷积
### 一、从特征信息角度：卷积层对图像的“取舍”

#### 卷积层提取的信息
- **局部空间相关性（local correlation）**  
    - 卷积核在局部区域滑动，能捕获边缘、纹理、形状等局部特征。
- **通道间的组合特征（cross-channel patterns）**  
    - 多通道输入的卷积核可学习到不同通道特征之间的关系，比如颜色与亮度的组合、不同语义层的融合。
- **空间不变性（translation invariance）**  
    - 特征提取与位置无关，卷积在平移后仍能检测出相同模式。

#### 同时丢失的信息
- **全局位置信息（global spatial location）**  
    - 因为卷积是局部滑动的、且共享权重，所以它不记录“在图像的哪个绝对位置”出现了某特征。
- **部分高频细节**  
    - 小卷积核、下采样操作会导致精细纹理、边缘细节的损失。
- **不可逆性（信息压缩）**  
    - 每一层卷积通常比输入维度小，且有非线性激活，意味着这是一个**信息压缩映射**（很多输入可能映射到相同输出）。

可以把卷积层看作是一种**“压缩+翻译”的过程**：
- 输入是像素级别的“生数据”；
- 卷积核通过局部计算，把这些像素转化成“模式强度”；
- 每个通道就像是一种“语义探测器”；
- 通道越深，捕获的模式越复杂；
- 代价是：图像的空间分辨率与细节逐渐消失。

#### 不同大小的卷积层特性
##### 1x1：参数少、学通道间关系
不改变空间尺寸，只做通道混合，例如从 64 通道 → 32 通道，是一个“信息压缩器”。
对不同特征通道加权整合
##### 3x3：参数多、学局部空间模式
能捕捉「局部空间相关性」；
比 5×5 或 7×7 更高效；是 CNN 的“最小有效视野”。
如果叠两层 3×3，等效于 5×5 的感受野，但参数更少
![[Pasted image 20251025161331.png]]
使用两个3x3卷积层替代一个5x5卷积层，主要有三大优势：
1. **参数更少**：如上计算，在保持输入输出通道数一致时，参数从 25C² 减少到 18C²，节省了28%。这减少了模型复杂度和过拟合的风险。
2. **更强的非线性能力**：两个卷积层意味着中间夹着两个激活函数（如ReLU），而一个5x5卷积层后面只有一个激活函数。更多的非线性变换使得模型的决策函数更具判别力。
3. **计算效率可能更高**：虽然两次操作，但由于3x3卷积是现代GPU（如使用NVIDIA的cuDNN库）高度优化的操作，其计算效率可能高于一次大的5x5卷积。
正是由于这些优点，这个设计原则被广泛应用于VGGNet、ResNet等经典的现代CNN架构中。


## Transformer

卷积的感受野局限于小区域，而遥感变化往往是跨大范围的结构差异。
例如：一条新修的道路；一个工地变成建筑；
这些变化需要“全局一致性”的特征。

Transformer 通过自注意力：
**对每个像素，计算它与整张图其它像素的相似度；**
**让网络“知道这块地的变化在整个图中是否合理”。**


## 模型训练
| 曲线形态                                 | 说明                       |
| ------------------------------------ | ------------------------ |
| 🔹 **两条曲线都高并且缓慢下降**                  | 欠拟合 — 模型还没学到规律（增加 epoch） |
| 🔹 **两条曲线接近并一起下降**                   | 正常拟合 — 模型在健康学习           |
| 🔹 **train loss 继续降，但 val loss 开始升** | 过拟合 — 模型开始“记答案”          |
| 🔹 **两条都不降**                         | 学习率太小、梯度爆炸或数据有误          |



### 关于loss问题的总结

![[实验/myplot.png]]
分析：train稳步下降说明训练有效，无过拟合，不是学习率的问题 bach也合适，
但是val震荡不降，并且一直保持在0.5-0.7之间
考虑验证集未归一化 / 标签插值错误，统一 train/val transform，标签 NEAREST 插值
![[myplot1.png]]
#### ✅ 结论总结

|现象|诊断|解决方式|
|---|---|---|
|Train 平滑下降，Val 抖动不降|验证集未归一化 / 标签插值错误|统一 train/val transform，标签 NEAREST 插值|
|Val 抖动但大体趋势下降|验证集样本太少|增加验证样本或多次评估平均|
|Val loss 稳定高于 train|模型轻微过拟合|启用早停 / 正则化 / dropout|
|两者一起下降到稳定低点|正常拟合|✅ 继续训练或保存最优模型|
[loss问题汇总（不收敛、震荡、nan） - 知乎](https://zhuanlan.zhihu.com/p/420053831)